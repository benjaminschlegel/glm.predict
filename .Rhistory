df_evaluation$disliked_text2))
df_evaluation$suggestion = ifelse(!is.na(df_evaluation$suggestion), df_evaluation$suggestion,
ifelse(!is.na(df_evaluation$suggestion1), df_evaluation$suggestion1,
df_evaluation$suggestion2))
df_evaluation$comments = ifelse(!is.na(df_evaluation$comments), df_evaluation$comments,
ifelse(!is.na(df_evaluation$comments1), df_evaluation$comments1,
df_evaluation$comments2))
df_evaluation = df_evaluation %>% select(event_name, person_type, event_like, organisation, correspondence, explanation, correct_and_neutral,
event_duration, event_balanced, learned, moderation_overall, moderation_neutrality, moderation_balanced_time,
discussit_heared_from, liked_text, disliked_text, suggestion, comments, political_interest:discussit_mehrwert)
df_evaluation$event_like = rowSums(df_evaluation %>% select(event_like:event_like2), na.rm = TRUE) * NA ^ (rowSums(!is.na(df_evaluation %>% select(event_like:event_like2))) == 0)
df_evaluation = df_evaluation %>% select(event_name, person_type, event_like, organisation, correspondence, explanation, correct_and_neutral,
event_duration, event_balanced, learned, moderation_overall, moderation_neutrality, moderation_balanced_time,
discussit_heared_from, liked_text, disliked_text, suggestion, comments, political_interest:discussit_mehrwert)
unique(df_evaluation$event_name)
na.omit(unique(df_evaluation$event_name))
df_event
event = unique(df_evaluation$event_name)[1]
event
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.align="center")
library(tidyverse)
library(quanteda)
library(knitr)
library(kableExtra)
df_event = df_evaluation %>% filter(event == event_name)
df_event
event = unique(df_evaluation$event_name)[2]
df_event = df_evaluation %>% filter(event == event_name)
df_event
install.packages("fastDummies")
fastDummies::dummy_cols
predProb = function(model, x_values, n){
betas = coef(model) # model
vcov = vcov(model) # model
betas_sim = MASS::mvrnorm(n, betas, vcov) # n
x = x_values # x
yhat = betas_sim %*% x
pred = exp(yhat) / (1 + exp(yhat))
conf.int = quntile(pred, probs = c(0.025, 0.975))
c(conf.int[1], mean(pred), conf.int[2])
}
df_selects = schlegel::selects2015
model_logit = glm(participation ~ age * gender,
family = "binomial", data = df_selects)
predProb(model_logit, (1, 24, 0, 0), 1000)
predProb = function(model, x_values, n){
betas = coef(model) # model
vcov = vcov(model) # model
betas_sim = MASS::mvrnorm(n, betas, vcov) # n
x = x_values # x
yhat = betas_sim %*% x
pred = exp(yhat) / (1 + exp(yhat))
conf.int = quantile(pred, probs = c(0.025, 0.975))
c(conf.int[1], mean(pred), conf.int[2])
}
predProb(model_logit, (1, 24, 0, 0), 1000)
predProb(model_logit, c(1, 24, 0, 0), 1000)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
df_selects = schlegel::selects2015
summary(df_selects$age)
model_glm = glm(participation ~ age * gender, binomial, df_selects)
install.packages("tinyrex")
install.packages("tinytex")
devtools::install_github("benjaminschlegel/glm.predict")
install.packages("digest")
devtools::install_github("benjaminschlegel/glm.predict")
df_selects = schlegel::selects2015
model_lm = lm(lr_self ~ age * gender + opinion_eu_membership, data = df_selects)
model_glm = glm(participation ~ age * gender + opinion_eu_membership, binomial, data = df_selects)
library(MASS)
moldel_polr = polr(opinion_eu_membership ~ age * gender + opinion_nuclear_energy, data = df_selects, Hess = TRUE)
model_polr = polr(opinion_eu_membership ~ age * gender + opinion_nuclear_energy, data = df_selects, Hess = TRUE)
library(nnet)
model_multinom = multinom(vote_choice ~ age * gender + opinion_eu_membership, data = df_selects)
library(glm.predict)
predicts(model_lm, "18-80;F;F")
predicts(model_lm, "18-80;F,F")
predicts(model_lm, "18-80;F;F")
predicts(model_lm, "18-80;mean;F")
predicts(model_lm, "18-80;F;F")
predicts(model_glm, "18-80;F;F")
predicts(model_polr, "mean;F;F", type = "boostrap")
predicts(model_polr, "mean;F;F", type = "bootstrap")
predicts(model_polr, "mean;F;F", positon = 2, type = "bootstrap")
predicts(model_polr, "mean;F;F", position = 2, type = "bootstrap")
devtools::install_github("benjaminschlegel/glm.predict")
df_selects = schlegel::selects2015
model_lm = lm(lr_self ~ age * gender + opinion_eu_membership, data = df_selects)
model_glm = glm(participation ~ age * gender + opinion_eu_membership, binomial, data = df_selects)
library(MASS)
model_polr = polr(opinion_eu_membership ~ age * gender + opinion_nuclear_energy, data = df_selects, Hess = TRUE)
library(nnet)
model_multinom = multinom(vote_choice ~ age * gender + opinion_eu_membership, data = df_selects)
library(glm.predict)
predicts(model_polr, "mean;F;F")
predicts(model_multinom, "mean;F;F")
library(glm.predict)
vignette(glm.predict)
vignette("glm.predict")
vignette("predicts")
?glm.predict
library(quanteda)
df_affairs = schlegel::affairs
df_inaugural = docvars(data_corpus_inaugural)
View(df_inaugural)
ntoken(data_corpus_inaugural)
View(df_inaugural)
ntype(data_corpus_inaugural)
head(df_inaugural)
install.packages("cld2")
df_affairs = cld2::detect_language(df_affairs$text)
cld2::detect_language(df_affairs$text)
df_affairs
df_affairs = schlegel::affairs
df_affairs$text = cld2::detect_language(df_affairs$text)
View(df_affairs)
table(df_affairs$text)
?corpus
# Corpus erstellen
corpus_affairs = df_affairs %>%
corpus(text_field = "text")
remove(df_inaugural)
?dfm
stopwords("de")
?tokens
install.packages("dlstats")
dlstats::cran_stats("glm.prediczt")
dlstats::cran_stats("glm.predict")
sum(dlstats::cran_stats("glm.predict")$download)
sum(dlstats::cran_stats("brant")$download)
sum(dlstats::cran_stats("quanteda")$download)
data("cbpp", package = "lme4")
head(cbpp)
?tokens
#
tokens_affairs = corpus_affairs %>%
tokens(remove_punct = F)
tokens_affairs
df_affairs = schlegel::affairs
# Sprache erkennen
df_affairs$lang = cld2::detect_language(df_affairs$text)
# Corpus erstellen
corpus_affairs = df_affairs %>%
corpus(text_field = "text")
#
tokens_affairs = corpus_affairs %>%
tokens(remove_punct = F)
tokens_affairs
# HTML Tags aus dem Text entfernen
library(rvest)
strip_html <- function(s) {
html_text(read_html(s))
}
strip_html <- function(s) {
html_text(read_html(s))
}
df_affairs$text = strip_html(df_affairs$text)
?html_text
strip_html <- function(s) {
html_text(s)
}
df_affairs$text = strip_html(df_affairs$text)
df_affairs$text = sapply(df_affairs$text, strip_html)
strip_html <- function(s) {
html_text(read_html(s))
}
df_affairs$text = sapply(df_affairs$text, strip_html)
df_affairs$text
# Sprache erkennen
df_affairs$lang = cld2::detect_language(df_affairs$text)
# Corpus erstellen
corpus_affairs = df_affairs %>%
corpus(text_field = "text")
# Corpus erstellen
corpus_affairs = df_affairs %>%
corpus(text_field = "text")
#
tokens_affairs = corpus_affairs %>%
tokens(remove_punct = F)
tokens_affairs
# in Tokens umwandeln
tokens_affairs = corpus_affairs %>%
tokens(remove_punct = TRUE) %>%
tokens_remove(stopwords("de")) %>%
tokens_tolower()
tokens_affairs
# document-feature matrix (dfm) erstellen
dfm_affairs = tokens_affairs %>%
tokens_wordstem(language = "de") %>%
dfm()
# Wortwolke erstellen
textplot_wordcloud(dfm)
# Wortwolke erstellen
textplot_wordcloud(dfm_affairs)
# in Tokens umwandeln
tokens_affairs = corpus_affairs %>%
tokens(remove_punct = TRUE) %>%
tokens_remove(c(stopwords("de"),"dass")) %>%
tokens_tolower()
# document-feature matrix (dfm) erstellen
dfm_affairs = tokens_affairs %>%
tokens_wordstem(language = "de") %>%
dfm()
# Wortwolke erstellen
textplot_wordcloud(dfm_affairs)
?stopwords
# in Tokens umwandeln
tokens_affairs = corpus_affairs %>%
tokens(remove_punct = TRUE) %>%
tokens_remove(c(stopwords("de", source = "stopwords-iso"))) %>%
tokens_tolower()
# document-feature matrix (dfm) erstellen
dfm_affairs = tokens_affairs %>%
tokens_wordstem(language = "de") %>%
dfm()
# Wortwolke erstellen
textplot_wordcloud(dfm_affairs)
# Wortwolke erstellen
textplot_wordcloud(dfm_affairs, max_words = 100)
# Wortwolke erstellen
textplot_wordcloud(dfm_affairs, max_words = 100, comparison = TRUE)
docvars(dfm_affairs)
dfm_affairs_party = dfm_affairs %>% dfm_group(groups = party)
dfm_affairs_party = dfm_affairs %>% dfm_group(groups = "party")
dfm_affairs_party
library(tidyverse)
table(df_affairs$party)
df_affairs = df_affairs %>% mutate(
party = recode(party, SVP = SVP, "FDP-Liberale" = FDP, glp = GLP,
SP = SP, GPS = GPS, CVP = CVP, BDP = BDP, .default = andere)
)
df_affairs = df_affairs %>% mutate(
party = recode(party, "SVP" = "SVP", "FDP-Liberale" = "FDP", "glp" = "GLP",
"SP" = "SP", "GPS" = "GPS", "CVP" = "CVP", "BDP" = "BDP",
.default = "andere")
)
df_affairs$party
table(df_affairs$party)
# HTML Tags aus dem Text entfernen
library(rvest)
strip_html <- function(s) {
html_text(read_html(s))
}
df_affairs$text = sapply(df_affairs$text, strip_html)
# Sprache erkennen
df_affairs$lang = cld2::detect_language(df_affairs$text)
# Corpus erstellen
corpus_affairs = df_affairs %>%
corpus(text_field = "text")
# in Tokens umwandeln
tokens_affairs = corpus_affairs %>%
tokens(remove_punct = TRUE) %>%
tokens_remove(c(stopwords("de", source = "stopwords-iso"))) %>%
tokens_tolower()
# document-feature matrix (dfm) erstellen
dfm_affairs = tokens_affairs %>%
tokens_wordstem(language = "de") %>%
dfm()
dfm_affairs_party = dfm_affairs %>% dfm_group(groups = "party")
# Wortwolke erstellen
textplot_wordcloud(dfm_affairs, max_words = 100, comparison = TRUE)
# Wortwolke erstellen
textplot_wordcloud(dfm_affairs_party, max_words = 100, comparison = TRUE)
# Wortwolke erstellen
textplot_wordcloud(dfm_affairs_party, max_words = 100, comparison = TRUE)
# Wortwolke erstellen
textplot_wordcloud(dfm_affairs_party, max_words = 100)
docvars(dfm_affairs_party)
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party, max_words = 100,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party, max_words = 100,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party, max_words = 100,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party, max_words = 100,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party, max_words = 100,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"),
labelcolor = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party, max_words = 30,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party, max_words = 200,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
warnings()
df_affairs = df_affairs %>% mutate(
party = recode(party, "SVP" = "SVP", "FDP-Liberale" = "FDP", "glp" = "GLP",
"SP" = "SP", "GPS" = "GPS", "CVP" = "CVP", "BDP" = "BDP",
.default = NA_character_)
)
# Corpus erstellen
corpus_affairs = df_affairs %>%
corpus(text_field = "text")
# in Tokens umwandeln
tokens_affairs = corpus_affairs %>%
tokens(remove_punct = TRUE) %>%
tokens_remove(c(stopwords("de", source = "stopwords-iso"))) %>%
tokens_tolower()
# document-feature matrix (dfm) erstellen
dfm_affairs = tokens_affairs %>%
tokens_wordstem(language = "de") %>%
dfm()
dfm_affairs_party = dfm_affairs %>% dfm_group(groups = "party")
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#757575", "#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
docvars(dfm_affairs_party)
df_affairs = schlegel::affairs
df_affairs = df_affairs %>% mutate(
party = recode(party, "SVP" = "SVP", "FDP-Liberale" = "FDP", "glp" = "GLP",
"SP" = "SP", "GPS" = "GPS", "CVP" = "CVP", "BDP" = "BDP",
.default = NA_character_)
)
# HTML Tags aus dem Text entfernen
library(rvest)
strip_html <- function(s) {
html_text(read_html(s))
}
df_affairs$text = sapply(df_affairs$text, strip_html)
# Sprache erkennen
df_affairs$lang = cld2::detect_language(df_affairs$text)
# Corpus erstellen
corpus_affairs = df_affairs %>%
corpus(text_field = "text")
# in Tokens umwandeln
tokens_affairs = corpus_affairs %>%
tokens(remove_punct = TRUE) %>%
tokens_remove(c(stopwords("de", source = "stopwords-iso"))) %>%
tokens_tolower()
# document-feature matrix (dfm) erstellen
dfm_affairs = tokens_affairs %>%
tokens_wordstem(language = "de") %>%
dfm()
dfm_affairs_party = dfm_affairs %>% dfm_group(groups = "party")
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"))
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"),
max_size = 3, min_size = 0.4)
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"),
max_size = 3, min_size = 0.4)
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"),
max_size = 3, min_size = 0.4,
max_words = 200)
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"),
max_size = 3, min_size = 0.4,
max_words = 200)
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"),
max_size = 3, min_size = 0.4,
max_words =500)
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"),
max_size = 3, min_size = 0.4, rotation = 0.2)
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"),
max_size = 3, min_size = 0.4, rotation = 0)
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"),
max_size = 3, min_size = 0.4, rotation = 0.1)
# in Tokens umwandeln
tokens_affairs = corpus_affairs %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_remove(c(stopwords("de", source = "stopwords-iso"))) %>%
tokens_tolower()
# document-feature matrix (dfm) erstellen
dfm_affairs = tokens_affairs %>%
tokens_wordstem(language = "de") %>%
dfm()
dfm_affairs_party = dfm_affairs %>% dfm_group(groups = "party")
# Wortwolke erstellen
textplot_wordcloud(dfm_affairs_party, max_words = 100)
# Parteien vergleichen
textplot_wordcloud(dfm_affairs_party,
comparison = TRUE,
color = c("#998200", "#B56100", "#3872B5",
"#999900", "#5D8132", "#D0362E", "#4F9141"),
max_size = 3, min_size = 0.4, rotation = 0.1)
# Schlüsselwort im Kontext (kwic)
kwic(corpus_affairs, "Person")
# Schlüsselwort im Kontext (kwic)
kwic_person = kwic(corpus_affairs, "Person")
kwic_person$docname
kwic_person$from
kwic_person$pre
kwic_person$pre
View(kwic_person)
i = 0.1
i = i + 0.05
i
i == 0.15
0.1 + 0.05 == 0.15
(0.1 + 0.05) == 0.15
0.1 + 0.05 == 0.15
(0.1 + 0.05) == 0.15
round(0.1 + 0.05,2) == 0.15
sprintf("%.54f",0.15)
sprintf("%.54f",0.1+0.05)
?all.equal
all.equal(0.15, 0.1+0.05)
all.equal(0.15, 0.1+0.05, 0.5)
?isTRUE
TRUE == NA
isTRUE(NA)
?brms::brm
install.packages("brms")
?brms::brm
load("~/GitHub/schlegel/data/selects2015.RData")
remove(.Random.seed)
save.image("~/GitHub/schlegel/data/selects2015.RData")
system("R CMD build schlegel")
setwd("GitHub")
system("R CMD build schlegel")
system("R CMD check schlegel_0.0.3.tar.gz")
system("R CMD build schlegel --resave-data")
system("R CMD check schlegel_0.0.3.tar.gz")
system("R CMD build --resave-data")
system("R CMD build schlegel --resave-data")
system("R CMD check schlegel_0.0.3.tar.gz")
drat::insertPackage("schlegel_0.0.3.tar.gz", "/drat")
drat::insertPackage("schlegel_0.0.3.tar.gz", "C:\\Users\\Benjamin\\Documents\\GitHub\\drat")
devtools::check_rhub("glm.predict")
devtools::check("glm.predict_4.0-0.tar.gz --as-cran")
system("R CMD check glm.predict_4.0-0.tar.gz --as-cran")
system("R CMD build glm.predict")
system("R CMD check glm.predict_4.0-0.tar.gz --as-cran")
system("R CMD build glm.predict")
devtools::check_rhub("glm.predict")
devtools::release("glm.predict")
devtools::check_win_devel("glm.predict")
devtools::release("glm.predict")
devtools::release("glm.predict")
??use_cran_comments
usethis::use_cran_comments()
usethis::use_cran_comments("glm.predict")
setwd("glm.predict")
usethis::use_cran_comments()
devtools::release("glm.predict")
devtools::release()
